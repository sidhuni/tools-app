apiVersion: batch/v1
kind: CronJob
metadata:
  name: postgresql-backup
  namespace: postgresql
spec:
  schedule: "*/1 * * * *"  # Once a minute for testing
  concurrencyPolicy: Forbid
  jobTemplate:
    spec:
      template:
        spec:
          # This ensures the pod can write to the PVC on Rancher Desktop
          securityContext:
            fsGroup: 1001
          restartPolicy: OnFailure
          containers:
            - name: backup
              image: registry-1.docker.io/bitnami/postgresql:latest
              imagePullPolicy: IfNotPresent
              securityContext:
                runAsUser: 1001
              env:
                - name: PGUSER
                  value: "admin"
                - name: PGPASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: postgresql-secrets
                      key: user_password
              volumeMounts:
                - name: backup-storage
                  mountPath: /backups
              command:
              - /bin/sh
              - -c
              - |
                set -e
                
                # 1. Setup local environment
                export HOME=/tmp/1001
                mkdir -p $HOME/bin
                export PATH=$PATH:$HOME/bin
                cd /tmp

                # 2. Use the Bundled Installer (Uses .tar.gz which Bitnami has 'tar' for)
                echo "Downloading AWS CLI Bundled Installer..."
                curl -s "https://s3.amazonaws.com/aws-cli/awscli-bundle.tar.gz" -o "awscli-bundle.tar.gz"
                
                echo "Extracting using tar..."
                tar -xzf awscli-bundle.tar.gz
                
                echo "Installing AWS CLI..."
                # The bundled installer is a self-contained script
                ./awscli-bundle/install -i $HOME/aws-cli -b $HOME/bin/aws > /dev/null

                # 3. Set current date for folder name
                TIMESTAMP=$(date +%Y-%m-%d)
                echo "--- Starting S3 Backup for $TIMESTAMP ---"

                # 4. List all databases
                DB_LIST=$(psql -h postgresql -U "$PGUSER" -d postgres -At -c "SELECT datname FROM pg_database WHERE datistemplate = false AND datname != 'postgres';")

                # 5. Backup and Stream to S3
                for DB in $DB_LIST; do
                  echo "Backing up: $DB"
                  pg_dump -h postgresql -U "$PGUSER" "$DB" | gzip | aws s3 cp - s3://$BUCKET/$TIMESTAMP/$DB.sql.gz
                  echo "âœ… Uploaded $DB.sql.gz to S3"
                done
                
                echo "--- All backups finished successfully ---"
          volumes:
            - name: backup-storage
              persistentVolumeClaim:
                claimName: postgres-local-backups
